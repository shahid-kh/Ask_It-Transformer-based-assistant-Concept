{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V27IM_Vf8iOz",
        "colab_type": "text"
      },
      "source": [
        "# Transformer based Dialogue Model on Google  TaskMaster-2 DataSet-Inference\n",
        "\n",
        "Follow on Github : https://github.com/shahid-kh/ChatBot_Transformer\n",
        "\n",
        "\n",
        "Follow on Linkedin: http://linkedin.com/in/shahid-khan-3abab5193\n",
        "\n",
        "\n",
        "This code is inspired from official Tutorial of tensorflow:\n",
        "https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html\n",
        "\n",
        "I extended this work to use different dataset Google Taskmaster-2 to see interesting results on General chats as assistant for various tasks of daily routine eg. Food ordering,Flight booking etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1rJ8RN080Dc",
        "colab_type": "text"
      },
      "source": [
        "# Mount your Drive for PreTrained weights Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSfGUJsbGqir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f92be65-ce56-4109-984b-de49b039db75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/mydrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /mydrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpxQbM857wfo",
        "colab_type": "text"
      },
      "source": [
        "# Pip Installations for Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHb_nttv7vJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fddcddf8-0e7b-45a3-cd7c-9c2812f1882f"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFlF8gNL71nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3202510f-925b-4294-fb3e-257595d32aca"
      },
      "source": [
        "!pip install SpeechRecognition"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 106kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIR_zfd0D7Vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "2984420a-1fb6-4221-f8bd-3026793e4426"
      },
      "source": [
        "!pip install gTTS"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gTTS\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/0c/4ca77eca3b739a4a08360930643f58d714e302fee0d2f8c654e67d9af8e7/gTTS-2.1.1-py3-none-any.whl\n",
            "Collecting gtts-token>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gTTS) (4.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Building wheels for collected packages: gtts-token\n",
            "  Building wheel for gtts-token (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gtts-token: filename=gTTS_token-1.1.3-cp36-none-any.whl size=4096 sha256=0714271912ff09669cde550df0914057fd8676141aebef9d2179445db4b9f2b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/11/61/33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
            "Successfully built gtts-token\n",
            "Installing collected packages: gtts-token, gTTS\n",
            "Successfully installed gTTS-2.1.1 gtts-token-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-__xv6sV0C_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d360b94-9815-4aea-dae0-14015112a1d5"
      },
      "source": [
        "!pip install playsound"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: playsound in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4nqTAua89xn",
        "colab_type": "text"
      },
      "source": [
        "#Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92KNGsPqGbli",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import speech_recognition as sr\n",
        "from os import path\n",
        "import scipy\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCWmmVH9Cs7",
        "colab_type": "text"
      },
      "source": [
        "#Configuring TPU Strategy\n",
        "Dont forget to change runtime type to TPU before running this Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgEKMq2wnQtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "53a31408-9c1f-4f2d-e012-00db799a6d3b"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.106.67.2:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.106.67.2:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHov9Dm8UE9u",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess sentence before prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UN3Fa44APq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afYb5Ud_ULD2",
        "colab_type": "text"
      },
      "source": [
        "# Load Saved Tokenizer pickled at the time of training\n",
        "Change paths accordingly as per your saved weigths location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwWWA8CaL8iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/Pretrained_Weights/tokenizer_chatbot.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "VOCAB_SIZE=tokenizer.vocab_size\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
        "MAX_LENGTH = 40\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0imNURFcUiOT",
        "colab_type": "text"
      },
      "source": [
        "# Model Building\n",
        "We need to build complete model architecture and compile to load pre trained weights as we have saved weights only not the complete model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YjZrp4e-qOP",
        "colab_type": "text"
      },
      "source": [
        "# Attention Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqDAhUJEg8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LTs5chExAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q92zdwH-vfe",
        "colab_type": "text"
      },
      "source": [
        "#Masks as per paper from Transfomers architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VKpsR-FHVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsaIYkf0FLCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0YVdih7-3Fu",
        "colab_type": "text"
      },
      "source": [
        "#Positional encoding as we are not using RNN/LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BED5y4YFSPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aONnbQak-_oy",
        "colab_type": "text"
      },
      "source": [
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqX_dqYCFfeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tguZtIKFuu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_xoYPw_CLQ",
        "colab_type": "text"
      },
      "source": [
        "#Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HFSma3F_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73I5VbJGD-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHQXSdQ_Ee4",
        "colab_type": "text"
      },
      "source": [
        "#Transformer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cE7vkaGGg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwkc16a5_IMK",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VBZCQjGUlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 6 #2,6\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8  #8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1DUGnwn_MO-",
        "colab_type": "text"
      },
      "source": [
        "#Loss Function,Accuracy and Custom learning rate scheduler\n",
        "Feel free to experiment with learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTRJel9Ga8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxhBOxYGcue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUssHnwGlCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbkcnqpx_Veb",
        "colab_type": "text"
      },
      "source": [
        "#Building model with TPU strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFNX-Ovo278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoPrGD6KU9xe",
        "colab_type": "text"
      },
      "source": [
        "# Load Pre trained weights from h5 file provided\n",
        "Change saved paths accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JT7kaSUMXCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/Pretrained_Weights/chat_trnsfrmer.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV5pXEmF_kmY",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2W874bBHCXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('You: {}'.format(sentence))\n",
        "  print('Assistant: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huW0P_gJ_tcl",
        "colab_type": "text"
      },
      "source": [
        "# Test Model responses in Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpmbuOWHMzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a987ce4-3eb4-487f-e169-458d6128c593"
      },
      "source": [
        "output = predict('i would like to order food')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: i would like to order food\n",
            "Output: what type of food would you like ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXIGmN_ECxM6",
        "colab_type": "text"
      },
      "source": [
        "# Setting Up Browser Speech recognition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3a2-ztC_iCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Listening you..\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Listening you... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Responding... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio,sr"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFps6GS_tK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def record_write_wav():\n",
        " \n",
        "  audio,sr= get_audio()\n",
        "  scipy.io.wavfile.write(\"recording.wav\", sr, audio)\n",
        "\n",
        "\n",
        "import speech_recognition as sr\n",
        "def recognize():\n",
        "  r = sr.Recognizer()\n",
        "  with sr.AudioFile(\"recording.wav\") as source:\n",
        "    audio = r.record(source)  # read the entire audio file\n",
        "\n",
        "\n",
        "# recognize speech using Google Speech Recognition\n",
        "  try:\n",
        "    # for testing purposes, we're just using the default API key\n",
        "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
        "    # instead of `r.recognize_google(audio)`\n",
        "    output=r.recognize_google(audio)\n",
        "    #print(\"Google Speech Recognition thinks you said \" + output)\n",
        "    return output\n",
        "\n",
        "  except sr.UnknownValueError:\n",
        "    print(\"Google Speech Recognition could not understand audio\")\n",
        "  except sr.RequestError as e:\n",
        "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhsoK8Tx_286",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Convert_Speech_to_Text():\n",
        "  #audio,sr= get_audio()\n",
        "  record_write_wav()\n",
        "  output=recognize()\n",
        "  return output\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmgvYd_H2sxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Start_Talking():\n",
        "  User=Convert_Speech_to_Text()\n",
        "  #print(User)\n",
        "  if(User==\"stop\"):\n",
        "    return \"stop\"\n",
        "  Response=predict(User)\n",
        " \n",
        "  tts = gTTS(Response) #Provide the string to convert to speech\n",
        "  tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "  sound_file = '1.wav'\n",
        "  display(Audio(sound_file,autoplay=True))\n",
        "  return User\n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BotVEqh_hz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Say_GoodBye():\n",
        "  tts = gTTS(\"It was nice talking to you, Have a nice day\") #Provide the string to convert to speech\n",
        "  tts.save('2.wav') #save the string converted to speech as a .wav file\n",
        "  bye_file = '2.wav'\n",
        "  display(Audio(bye_file,autoplay=True))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTLhBZl-V53",
        "colab_type": "text"
      },
      "source": [
        "# Enjoy talking to your assistant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ6swe7o_5k7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "2c54f50d-c4b4-4834-ee75-0ba3b88439f1"
      },
      "source": [
        "while(True):\n",
        "  Command=Start_Talking()\n",
        "  if(Command==\"stop\"):\n",
        "    Say_GoodBye()\n",
        "    break\n",
        "  \n",
        "  "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Listening you..\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Listening you... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Responding... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "You: I want to book a flight\n",
            "Assistant: okay , where are you coming from ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Listening you..\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Listening you... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Responding... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDG7bCzFayr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}