{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V27IM_Vf8iOz",
        "colab_type": "text"
      },
      "source": [
        "# Transformer based Dialogue Model on Google  TaskMaster-2 DataSet-Inference\n",
        "\n",
        "Follow on Github : https://github.com/shahid-kh/ChatBot_Transformer\n",
        "\n",
        "\n",
        "Follow on Linkedin: http://linkedin.com/in/shahid-khan-3abab5193\n",
        "\n",
        "\n",
        "This code is inspired from official Tutorial of tensorflow:\n",
        "https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html\n",
        "\n",
        "I extended this work to use different dataset called Google Taskmaster-2 to see interesting results on General chats as assistant for various tasks of daily routine eg. Food ordering,Flight booking etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1rJ8RN080Dc",
        "colab_type": "text"
      },
      "source": [
        "# Mount your Drive for PreTrained weights Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSfGUJsbGqir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29fe8db6-1594-43ff-977a-5c31918f10c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/mydrive\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /mydrive; to attempt to forcibly remount, call drive.mount(\"/mydrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpxQbM857wfo",
        "colab_type": "text"
      },
      "source": [
        "# Pip Installations for Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHb_nttv7vJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e9860e8-37c5-49f2-e280-ee1bf9623912"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFlF8gNL71nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1df457c-a910-409c-d02c-5997b207bd32"
      },
      "source": [
        "!pip install SpeechRecognition"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.6/dist-packages (3.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIR_zfd0D7Vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c5ee54c4-d7c4-4d88-9da1-6c1dcd1b3978"
      },
      "source": [
        "!pip install gTTS"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gTTS) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: gtts-token>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from gTTS) (1.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-__xv6sV0C_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d360b94-9815-4aea-dae0-14015112a1d5"
      },
      "source": [
        "!pip install playsound"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: playsound in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4nqTAua89xn",
        "colab_type": "text"
      },
      "source": [
        "#Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92KNGsPqGbli",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import speech_recognition as sr\n",
        "from os import path\n",
        "import scipy\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCWmmVH9Cs7",
        "colab_type": "text"
      },
      "source": [
        "#Configuring TPU Strategy\n",
        "Dont forget to change runtime type to TPU before running this Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgEKMq2wnQtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "37b5219d-1eef-4d62-a696-074ed947b79a"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.126.170.138:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.126.170.138:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHov9Dm8UE9u",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess sentence before prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UN3Fa44APq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afYb5Ud_ULD2",
        "colab_type": "text"
      },
      "source": [
        "# Load Saved Tokenizer pickled at the time of training\n",
        "Change paths accordingly as per your saved weigths location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwWWA8CaL8iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/Pretrained_Weights/tokenizer_chatbot.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "VOCAB_SIZE=tokenizer.vocab_size\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
        "MAX_LENGTH = 40\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0imNURFcUiOT",
        "colab_type": "text"
      },
      "source": [
        "# Model Building\n",
        "We need to build complete model architecture and compile to load pre trained weights as we have saved weights only not the complete model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YjZrp4e-qOP",
        "colab_type": "text"
      },
      "source": [
        "# Attention Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqDAhUJEg8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LTs5chExAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q92zdwH-vfe",
        "colab_type": "text"
      },
      "source": [
        "#Masks as per paper from Transfomers architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VKpsR-FHVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsaIYkf0FLCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0YVdih7-3Fu",
        "colab_type": "text"
      },
      "source": [
        "#Positional encoding as we are not using RNN/LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BED5y4YFSPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aONnbQak-_oy",
        "colab_type": "text"
      },
      "source": [
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqX_dqYCFfeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tguZtIKFuu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_xoYPw_CLQ",
        "colab_type": "text"
      },
      "source": [
        "#Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HFSma3F_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73I5VbJGD-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHQXSdQ_Ee4",
        "colab_type": "text"
      },
      "source": [
        "#Transformer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cE7vkaGGg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwkc16a5_IMK",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VBZCQjGUlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 6 #2,6\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8  #8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1DUGnwn_MO-",
        "colab_type": "text"
      },
      "source": [
        "#Loss Function,Accuracy and Custom learning rate scheduler\n",
        "Feel free to experiment with learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTRJel9Ga8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxhBOxYGcue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUssHnwGlCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbkcnqpx_Veb",
        "colab_type": "text"
      },
      "source": [
        "#Building model with TPU strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFNX-Ovo278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoPrGD6KU9xe",
        "colab_type": "text"
      },
      "source": [
        "# Load Pre trained weights from h5 file provided\n",
        "Change saved paths accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JT7kaSUMXCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/Pretrained_Weights/chat_trnsfrmer.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV5pXEmF_kmY",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2W874bBHCXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huW0P_gJ_tcl",
        "colab_type": "text"
      },
      "source": [
        "# Test Model responses in Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpmbuOWHMzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbf2a0bb-15d6-42fc-cd1c-9719672413b0"
      },
      "source": [
        "output = predict('i would like to order food')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: i would like to order food\n",
            "Output: what type of food would you like ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXIGmN_ECxM6",
        "colab_type": "text"
      },
      "source": [
        "# Setting Up Browser Speech recognition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3a2-ztC_iCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio,sr"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFps6GS_tK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def record_write_wav():\n",
        " \n",
        "  audio,sr= get_audio()\n",
        "  scipy.io.wavfile.write(\"recording.wav\", sr, audio)\n",
        "\n",
        "\n",
        "import speech_recognition as sr\n",
        "def recognize():\n",
        "  r = sr.Recognizer()\n",
        "  with sr.AudioFile(\"recording.wav\") as source:\n",
        "    audio = r.record(source)  # read the entire audio file\n",
        "\n",
        "\n",
        "# recognize speech using Google Speech Recognition\n",
        "  try:\n",
        "    # for testing purposes, we're just using the default API key\n",
        "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
        "    # instead of `r.recognize_google(audio)`\n",
        "    output=r.recognize_google(audio)\n",
        "    #print(\"Google Speech Recognition thinks you said \" + output)\n",
        "    return output\n",
        "\n",
        "  except sr.UnknownValueError:\n",
        "    print(\"Google Speech Recognition could not understand audio\")\n",
        "  except sr.RequestError as e:\n",
        "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhsoK8Tx_286",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Convert_Speech_to_Text():\n",
        "  #audio,sr= get_audio()\n",
        "  record_write_wav()\n",
        "  output=recognize()\n",
        "  return output\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmgvYd_H2sxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Start_Talking():\n",
        "  User=Convert_Speech_to_Text()\n",
        "  Response=predict(User)\n",
        "  tts = gTTS(Response) #Provide the string to convert to speech\n",
        "  tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "  sound_file = '1.wav'\n",
        "  display(Audio(sound_file,autoplay=True))\n",
        "  return User\n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BotVEqh_hz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Say_GoodBye():\n",
        "  tts = gTTS(\"It was nice talking to you\") #Provide the string to convert to speech\n",
        "  tts.save('2.wav') #save the string converted to speech as a .wav file\n",
        "  bye_file = '2.wav'\n",
        "  display(Audio(bye_file,autoplay=True))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTLhBZl-V53",
        "colab_type": "text"
      },
      "source": [
        "# Enjoy talking to your assistant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ6swe7o_5k7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "70c8c47c-e6e6-45b2-8be7-41782a11153c"
      },
      "source": [
        "while(True):\n",
        "  Command=Start_Talking()\n",
        "  if(Command==\"Stop\"):\n",
        "    Say_GoodBye()\n",
        "    break\n",
        "  \n",
        "  "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Input: I would like to book a flight\n",
            "Output: okay , where are you traveling to ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Input: I would like to book a flight\n",
            "Output: okay , where are you traveling to ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1ee7d9fde330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mCommand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStart_Talking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Stop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSay_GoodBye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-9a048eb8efef>\u001b[0m in \u001b[0;36mStart_Talking\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mStart_Talking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mUser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConvert_Speech_to_Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mResponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Provide the string to convert to speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-faad9c3f613c>\u001b[0m in \u001b[0;36mConvert_Speech_to_Text\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert_Speech_to_Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#audio,sr= get_audio()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mrecord_write_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9e5d140f6724>\u001b[0m in \u001b[0;36mrecord_write_wav\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_write_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recording.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-2debba392189>\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_HTML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1ee7d9fde330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mCommand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStart_Talking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Stop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSay_GoodBye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-9a048eb8efef>\u001b[0m in \u001b[0;36mStart_Talking\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mStart_Talking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mUser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConvert_Speech_to_Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mResponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Provide the string to convert to speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-faad9c3f613c>\u001b[0m in \u001b[0;36mConvert_Speech_to_Text\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert_Speech_to_Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#audio,sr= get_audio()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mrecord_write_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9e5d140f6724>\u001b[0m in \u001b[0;36mrecord_write_wav\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_write_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recording.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-2debba392189>\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_HTML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDG7bCzFayr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9XkAP1jAEYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRbhVqnVDgKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTxvonfg8gK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HTML(play_beep)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}