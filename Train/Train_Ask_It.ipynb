{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V27IM_Vf8iOz",
        "colab_type": "text"
      },
      "source": [
        "# Transformer based Dialogue Model on Google  TaskMaster-2 DataSet\n",
        "\n",
        "Follow on Github : https://github.com/shahid-kh/ChatBot_Transformer\n",
        "\n",
        "\n",
        "Follow on Linkedin: http://linkedin.com/in/shahid-khan-3abab5193\n",
        "\n",
        "\n",
        "This code is inspired from official Tutorial of tensorflow:\n",
        "https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html\n",
        "\n",
        "I extended this work to use different dataset called Google Taskmaster-2 to see interesting results on General chats as assistant for various tasks of daily routine eg. Food ordering,Flight booking etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1rJ8RN080Dc",
        "colab_type": "text"
      },
      "source": [
        "# Mount your Drive for DataSet Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSfGUJsbGqir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "08266a67-1b3d-4bd5-8749-695bc717ae84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/mydrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /mydrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4nqTAua89xn",
        "colab_type": "text"
      },
      "source": [
        "#Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92KNGsPqGbli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8f5b2220-c7d8-465a-a5f3-f2eedb04db1d"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "!pip install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-datasets==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.22.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (49.2.0)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 2.1.0\n",
            "    Uninstalling tensorflow-datasets-2.1.0:\n",
            "      Successfully uninstalled tensorflow-datasets-2.1.0\n",
            "Successfully installed tensorflow-datasets-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCWmmVH9Cs7",
        "colab_type": "text"
      },
      "source": [
        "#Configuring TPU Strategy\n",
        "Dont forget to change runtime type to TPU before running this Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgEKMq2wnQtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ea099f31-95ac-4ee7-d2a5-9ec5626b9130"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.123.240.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.123.240.50:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g82oU2Zm9Oap",
        "colab_type": "text"
      },
      "source": [
        "# Reading Dataset From Google Drive\n",
        "\n",
        "Take care of file paths ,where your dataset is stored.adjust accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XXwNv9Sp_Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames=[]\n",
        "filepaths=[]\n",
        "data_list=[]\n",
        "file_init_path='/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/DataSet/'\n",
        "filenames=os.listdir('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/DataSet')\n",
        "\n",
        "for file in filenames:\n",
        "  path=file_init_path+file\n",
        "  filepaths.append(path)\n",
        "  \n",
        "for file in filepaths:\n",
        "  with open(file) as f:\n",
        "    data=json.load(f)\n",
        "    data_list.append(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CCprwJN9Tkq",
        "colab_type": "text"
      },
      "source": [
        "# PreProcessing Data and Extracting Conversations \n",
        "\n",
        "For detailed data understandin,go to Google Research page\n",
        "https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8eHy741GoQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f7132b5-089f-4f9f-aeac-171144b90a09"
      },
      "source": [
        "conversation=[]\n",
        "for data in data_list:\n",
        "\n",
        "  for line in data:\n",
        "    conversation.append(line['utterances'])\n",
        "\n",
        "print(len(conversation))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UN3Fa44APq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiaH_rWJ9swR",
        "colab_type": "text"
      },
      "source": [
        "#Separating data into Assistant and USER Sections.\n",
        "Question is asked by user and answer is given by assistant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRKqLeBczlB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USER=[]\n",
        "BOT=[]\n",
        "def add_text(speaker,text):\n",
        "  if (speaker==\"USER\"):\n",
        "    USER.append(preprocess_sentence(text))\n",
        "  elif (speaker==\"ASSISTANT\"):\n",
        "    BOT.append(preprocess_sentence(text))\n",
        "  else:\n",
        "    print(\"Error\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYwGQMMFyUtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_QA():\n",
        "  last_speaker=\"None\"\n",
        "  current_speaker=\"None\"\n",
        "  temp_text=\"\"\n",
        "  for segment in conversation:\n",
        "    for p in segment:\n",
        "      current_speaker=p['speaker']\n",
        "      if (last_speaker==\"None\"):\n",
        "        temp_text=temp_text+p['text']\n",
        "      \n",
        "      else:\n",
        "        if (current_speaker==last_speaker):\n",
        "          temp_text=temp_text+p['text']\n",
        "\n",
        "        else:\n",
        "          add_text(last_speaker,temp_text)\n",
        "          temp_text=\"\"\n",
        "          temp_text=temp_text+p['text']\n",
        "    \n",
        "      last_speaker=current_speaker\n",
        "\n",
        "  return BOT,USER\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOax2jzAAs2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions,answers=load_QA()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzyVe_kt9-Pi",
        "colab_type": "text"
      },
      "source": [
        "# Configuring questions as USER and Answers as Assistant "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DR-hTAWRq8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d6b78696-2269-4f86-a6d7-c859a93339f7"
      },
      "source": [
        "\n",
        "\n",
        "questions1=answers[0:142199]\n",
        "answers1=questions[1:142200]\n",
        "\n",
        "for i in range(142195,142199):\n",
        "  print(\"Q: \"+questions1[i])\n",
        "  print(\"An: \" +answers1[i])\n",
        "print(len(questions1))\n",
        "print(len(answers1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: first class .\n",
            "An: just one moment . i found one flight for , .\n",
            "Q: that sounds good .\n",
            "An: i have united flight leaving at am .\n",
            "Q: and the returning flight ?\n",
            "An: i have united flight leaving at am .\n",
            "Q: alright , i d like to book that .\n",
            "An: booking flight . was there anything else i can help you with ?\n",
            "142199\n",
            "142199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIjC9joK-FoQ",
        "colab_type": "text"
      },
      "source": [
        "# Train Validation Split\n",
        "For now, we will not be using validation data in training\n",
        "to be updated in next version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQEI7sx0c9qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train validation split ,TO be used later,Dont use fornow\n",
        "question_val = questions1[-10000:]\n",
        "answer_val = answers1[-10000:]\n",
        "questions1 = questions1[:-10000]\n",
        "answers1 = answers1[:-10000]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5KU0ETWxmW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cd4e5dba-7772-43f3-c301-b46d0f0df96b"
      },
      "source": [
        "\n",
        "print('Sample question: {}'.format(questions1[120327]))\n",
        "print('Sample answer: {}'.format(answers1[120327]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample question: sure , i need it from sacramento to salt lake city . i d like to leave today and return in days .\n",
            "Sample answer: do you want to leave the latest or earliest flight ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsV0Clex-TtP",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GqBEIwXoGpQq",
        "colab": {}
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions1 + answers1, target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRwJBJ85Dciy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e73c3652-4c1c-4741-914d-67cdc070271a"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions1[20])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [28, 17, 2, 50, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3AB6YFCDnTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions1, answers1 = tokenize_and_filter(questions1,answers1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjsojxVODyJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ee411cc-620c-4294-8dc8-dee9a3e745c4"
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8136\n",
            "Number of samples: 125671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nIyN6id-eIP",
        "colab_type": "text"
      },
      "source": [
        "# Conversion of Data to tf.Data.Dataset pipeline format for easy data operations shuffling,buffering etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DB7X7PiDoUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64  ##64,20000\n",
        "BUFFER_SIZE = 40000\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions1,\n",
        "        'dec_inputs': answers1[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers1[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oOhuh8tEexC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1a7723d4-081e-49c2-f992-19e7ef2be0c8"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ({inputs: (None, 40), dec_inputs: (None, 39)}, {outputs: (None, 39)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YjZrp4e-qOP",
        "colab_type": "text"
      },
      "source": [
        "# Attention Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqDAhUJEg8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LTs5chExAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q92zdwH-vfe",
        "colab_type": "text"
      },
      "source": [
        "#Masks as per paper from Transfomers architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VKpsR-FHVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsaIYkf0FLCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0YVdih7-3Fu",
        "colab_type": "text"
      },
      "source": [
        "#Positional encoding as we are not using RNN/LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BED5y4YFSPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aONnbQak-_oy",
        "colab_type": "text"
      },
      "source": [
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqX_dqYCFfeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tguZtIKFuu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_xoYPw_CLQ",
        "colab_type": "text"
      },
      "source": [
        "#Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HFSma3F_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73I5VbJGD-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHQXSdQ_Ee4",
        "colab_type": "text"
      },
      "source": [
        "#Transformer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cE7vkaGGg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwkc16a5_IMK",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VBZCQjGUlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 6 #2,6\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8  #8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1DUGnwn_MO-",
        "colab_type": "text"
      },
      "source": [
        "#Loss Function,Accuracy and Custom learning rate scheduler\n",
        "Feel free to experiment with learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTRJel9Ga8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxhBOxYGcue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUssHnwGlCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbkcnqpx_Veb",
        "colab_type": "text"
      },
      "source": [
        "#Building model with TPU strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFNX-Ovo278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtFR7oic_bdR",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1QIgVNGpHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "16595dda-bd61-4ed9-d22e-5084699c4221"
      },
      "source": [
        "EPOCHS =20\n",
        "\n",
        "history=model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   2/1964 [..............................] - ETA: 2:25 - loss: 0.9845 - accuracy: 0.1332WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0575s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0575s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1964/1964 [==============================] - 139s 71ms/step - loss: 0.8105 - accuracy: 0.1516\n",
            "Epoch 2/20\n",
            "1964/1964 [==============================] - 137s 70ms/step - loss: 0.7440 - accuracy: 0.1587\n",
            "Epoch 3/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.6919 - accuracy: 0.1654\n",
            "Epoch 4/20\n",
            "1964/1964 [==============================] - 141s 72ms/step - loss: 0.6569 - accuracy: 0.1700\n",
            "Epoch 5/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.6313 - accuracy: 0.1734\n",
            "Epoch 6/20\n",
            "1964/1964 [==============================] - 144s 74ms/step - loss: 0.6107 - accuracy: 0.1764\n",
            "Epoch 7/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.5944 - accuracy: 0.1786\n",
            "Epoch 8/20\n",
            "1964/1964 [==============================] - 141s 72ms/step - loss: 0.5800 - accuracy: 0.1807\n",
            "Epoch 9/20\n",
            "1964/1964 [==============================] - 141s 72ms/step - loss: 0.5671 - accuracy: 0.1826\n",
            "Epoch 10/20\n",
            "1964/1964 [==============================] - 142s 72ms/step - loss: 0.5557 - accuracy: 0.1844\n",
            "Epoch 11/20\n",
            "1964/1964 [==============================] - 143s 73ms/step - loss: 0.5447 - accuracy: 0.1860\n",
            "Epoch 12/20\n",
            "1964/1964 [==============================] - 142s 72ms/step - loss: 0.5347 - accuracy: 0.1876\n",
            "Epoch 13/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.5255 - accuracy: 0.1891\n",
            "Epoch 14/20\n",
            "1964/1964 [==============================] - 143s 73ms/step - loss: 0.5174 - accuracy: 0.1905\n",
            "Epoch 15/20\n",
            "1964/1964 [==============================] - 144s 73ms/step - loss: 0.5096 - accuracy: 0.1917\n",
            "Epoch 16/20\n",
            "1964/1964 [==============================] - 139s 71ms/step - loss: 0.5024 - accuracy: 0.1927\n",
            "Epoch 17/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.4960 - accuracy: 0.1940\n",
            "Epoch 18/20\n",
            "1964/1964 [==============================] - 140s 71ms/step - loss: 0.4890 - accuracy: 0.1952\n",
            "Epoch 19/20\n",
            "1964/1964 [==============================] - 138s 71ms/step - loss: 0.4831 - accuracy: 0.1963\n",
            "Epoch 20/20\n",
            "1964/1964 [==============================] - 144s 73ms/step - loss: 0.4774 - accuracy: 0.1972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgj2IRhS_hST",
        "colab_type": "text"
      },
      "source": [
        "#Plotting Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAepTGvBrg6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYDg-8prrquV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96ed9fd9-d8e9-4918-a80c-cba691194da8"
      },
      "source": [
        "epoch_no=[i for i in range(1,21)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddNvxwjTuNjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "eb441e03-1cd9-4865-9417-940ca9914da5"
      },
      "source": [
        "#LOSS\n",
        "fig=plt.figure()\n",
        "ax=fig.add_subplot(1,1,1)\n",
        "ax.set_title(' Training Loss Curve')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "ax.plot(epoch_no,history.history['loss'])\n",
        "plt.savefig('/content/loss_chat.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXzcl8DTvHQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f7124eda-a40d-40e7-fe05-ac7e9fd7f589"
      },
      "source": [
        "#Accuracy\n",
        "fig=plt.figure()\n",
        "ax1=fig.add_subplot(1,1,1)\n",
        "ax1.set_title(' Training Accuracy Curve')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "\n",
        "ax1.plot(epoch_no,history.history['accuracy'])\n",
        "plt.savefig('/content/accuracy_chat.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV5pXEmF_kmY",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2W874bBHCXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huW0P_gJ_tcl",
        "colab_type": "text"
      },
      "source": [
        "# Talk with your newly trained Friend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpmbuOWHMzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad59bdf1-3fe2-4c0a-ba98-a89face5cd7e"
      },
      "source": [
        "output = predict('i would like to order food')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: With Some cold Drink\n",
            "Output: okay , i have a few options for you .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNyg8_hCAxHb",
        "colab_type": "text"
      },
      "source": [
        "# Saving Tokenizer for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj75l2V2AoGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving tokenizer\n",
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/Pretrained_Weights/tokenizer_chatbot.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ZjZ6AY_5pw",
        "colab_type": "text"
      },
      "source": [
        "# Save weights as H5 so that next time you can use straightforward prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQvcqNpWzgJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/chat_trnsfrmer.h5', save_format='H5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0J3-OJgCP2C",
        "colab_type": "text"
      },
      "source": [
        "# Future Scope\n",
        "We saw how  basic transformer even can be trained on dailogue tasks like this,though it doesnt give accuracy because we only trained for 20 epochs due to processing constraints. but this gives a fair idea how dialogue models are trained while also giving you the real taste of transformer archtectures.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXIGmN_ECxM6",
        "colab_type": "text"
      },
      "source": [
        "# Happy Leaning ,Happy Coding\n",
        "\n"
      ]
    }
  ]
}
