{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSfGUJsbGqir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e18c6b41-b7d5-47f4-de97-ae1404539234"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/mydrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /mydrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92KNGsPqGbli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "4f6d6c24-1374-4a72-8c90-7c337550bf61"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "!pip install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-datasets==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 2.1MB/s eta 0:00:02\r\u001b[K     |▍                               | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 29kB/s eta 0:00:12\r\u001b[K     |███████████████████████████▌    | 1.9MB 29kB/s eta 0:00:11\r\u001b[K     |███████████████████████████▊    | 2.0MB 29kB/s eta 0:00:11\r\u001b[K     |███████████████████████████▉    | 2.0MB 29kB/s eta 0:00:11\r\u001b[K     |████████████████████████████    | 2.0MB 29kB/s eta 0:00:10\r\u001b[K     |████████████████████████████    | 2.0MB 29kB/s eta 0:00:10\r\u001b[K     |████████████████████████████▎   | 2.0MB 29kB/s eta 0:00:10\r\u001b[K     |████████████████████████████▍   | 2.0MB 29kB/s eta 0:00:09\r\u001b[K     |████████████████████████████▌   | 2.0MB 29kB/s eta 0:00:09\r\u001b[K     |████████████████████████████▊   | 2.0MB 29kB/s eta 0:00:08\r\u001b[K     |████████████████████████████▉   | 2.0MB 29kB/s eta 0:00:08\r\u001b[K     |█████████████████████████████   | 2.0MB 29kB/s eta 0:00:08\r\u001b[K     |█████████████████████████████▏  | 2.1MB 29kB/s eta 0:00:07\r\u001b[K     |█████████████████████████████▎  | 2.1MB 29kB/s eta 0:00:07\r\u001b[K     |█████████████████████████████▍  | 2.1MB 29kB/s eta 0:00:07\r\u001b[K     |█████████████████████████████▋  | 2.1MB 29kB/s eta 0:00:06\r\u001b[K     |█████████████████████████████▊  | 2.1MB 29kB/s eta 0:00:06\r\u001b[K     |█████████████████████████████▉  | 2.1MB 29kB/s eta 0:00:06\r\u001b[K     |██████████████████████████████  | 2.1MB 29kB/s eta 0:00:05\r\u001b[K     |██████████████████████████████▏ | 2.1MB 29kB/s eta 0:00:05\r\u001b[K     |██████████████████████████████▎ | 2.1MB 29kB/s eta 0:00:05\r\u001b[K     |██████████████████████████████▍ | 2.2MB 29kB/s eta 0:00:04\r\u001b[K     |██████████████████████████████▋ | 2.2MB 29kB/s eta 0:00:04\r\u001b[K     |██████████████████████████████▊ | 2.2MB 29kB/s eta 0:00:04\r\u001b[K     |██████████████████████████████▉ | 2.2MB 29kB/s eta 0:00:03\r\u001b[K     |███████████████████████████████ | 2.2MB 29kB/s eta 0:00:03\r\u001b[K     |███████████████████████████████▏| 2.2MB 29kB/s eta 0:00:03\r\u001b[K     |███████████████████████████████▎| 2.2MB 29kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████▍| 2.2MB 29kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████▋| 2.2MB 29kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 29kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.3MB 29kB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 29kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.22.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.12.2)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (49.2.0)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 2.1.0\n",
            "    Uninstalling tensorflow-datasets-2.1.0:\n",
            "      Successfully uninstalled tensorflow-datasets-2.1.0\n",
            "Successfully installed tensorflow-datasets-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgEKMq2wnQtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "adb4cc6e-e7c5-4b2b-adae-970ebb2211eb"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.63.197.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.63.197.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDOWoTaCINHp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "f66dab83-7fb3-4be1-9dd2-540bd4098fab"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLVulAcSxFbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XXwNv9Sp_Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames=[]\n",
        "filepaths=[]\n",
        "data_list=[]\n",
        "file_init_path='/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2/'\n",
        "filenames=os.listdir('/mydrive/My Drive/ChatBot_Trnsfrmer_Taskmaster2')\n",
        "\n",
        "for file in filenames:\n",
        "  path=file_init_path+file\n",
        "  filepaths.append(path)\n",
        "  \n",
        "for file in filepaths:\n",
        "  with open(file) as f:\n",
        "    data=json.load(f)\n",
        "    data_list.append(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wW_DzcNzJk1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d996f907-1a69-47ca-8aee-4b00c0224e8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8eHy741GoQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "add6dc0e-0e41-4022-cf68-9cd45ba4ffc3"
      },
      "source": [
        "conversation=[]\n",
        "for data in data_list:\n",
        "\n",
        "  for line in data:\n",
        "    conversation.append(line['utterances'])\n",
        "\n",
        "print(len(conversation))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UN3Fa44APq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRKqLeBczlB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USER=[]\n",
        "BOT=[]\n",
        "def add_text(speaker,text):\n",
        "  if (speaker==\"USER\"):\n",
        "    USER.append(preprocess_sentence(text))\n",
        "  elif (speaker==\"ASSISTANT\"):\n",
        "    BOT.append(preprocess_sentence(text))\n",
        "  else:\n",
        "    print(\"Error\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYwGQMMFyUtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_QA():\n",
        "  last_speaker=\"None\"\n",
        "  current_speaker=\"None\"\n",
        "  temp_text=\"\"\n",
        "  for segment in conversation:\n",
        "    for p in segment:\n",
        "      current_speaker=p['speaker']\n",
        "      if (last_speaker==\"None\"):\n",
        "        temp_text=temp_text+p['text']\n",
        "      \n",
        "      else:\n",
        "        if (current_speaker==last_speaker):\n",
        "          temp_text=temp_text+p['text']\n",
        "\n",
        "        else:\n",
        "          add_text(last_speaker,temp_text)\n",
        "          temp_text=\"\"\n",
        "          temp_text=temp_text+p['text']\n",
        "    \n",
        "      last_speaker=current_speaker\n",
        "\n",
        "  return BOT,USER\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOax2jzAAs2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "questions,answers=load_QA()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5KU0ETWxmW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e2708e4-172a-491c-d0fa-e721cd841969"
      },
      "source": [
        "\n",
        "print('Sample question: {}'.format(questions[120325]))\n",
        "print('Sample answer: {}'.format(answers[120352]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample question: no problem . have a great day .\n",
            "Sample answer: i would like to fly on delta .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWtQQ3zashNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(len(questions))\n",
        "#print(len(answers))\n",
        "questions1=questions[0:40000]\n",
        "answers1=answers[0:40000]\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5g5j_woza7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d23eef2-4484-4475-a3e9-e7af0daf953a"
      },
      "source": [
        "\n",
        "for i in range(2000,2200):\n",
        "  print(' Q '+questions1[i]+' A '+answers1[i])\n",
        "#print(answers1[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Q you re welcome . bye . A can you help me to order sandwiches for two people ?\n",
            " Q yes , i can help with your order . go ahead with the first order . A okay . i d like one to be on white bread with turkey , cranberry sauce and turkey gravy . and the second one to be a caprese with mozzarella , roma tomato , basil and balsamic .\n",
            " Q can you repeat your second order ? A yes , a caprese with fresh mozzarella , tomato , basil and balsamic .\n",
            " Q anything else ? A two lemonades .\n",
            " Q hold on . this will just be a second . to confirm your order . i have one turkey with cranberry sauce and turkey gravy on white bread , the second order is a caprese with mozzarella , tomato , basil and balsamic with two lemonades . anything else ? A nope , that will be everything .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you .\n",
            " Q hello , how can i help you ? A hi there . i want to order some mexican food for takeout .\n",
            " Q mexican food got it . what would you like to order ? A like two steak tacos with sour cream .\n",
            " Q two steak tacos with sour cream got it . anything else ? A two cheese enchiladas with sour cream .\n",
            " Q two cheese enchiladas with sour cream got it . anything else ? A i would like refried beans for two people .\n",
            " Q sides of refried beans . A and two sides of yellow rice , please .\n",
            " Q sides of yellow rice got it . anything else ? A no , thank you . that ll do it .\n",
            " Q ok , i have your personal details on file . your order will be ready for pick up in about minutes . A excellent ! thank you .\n",
            " Q thank you . how can i help you ? A i need help ordering takeout pasta for two people , please .\n",
            " Q okay . i can help with that . A i d like one lasagna with meat sauce and a side of two meatballs , one vegetable lasagna , four pieces of sourdough bread and , two cannoli s , which completes my order .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A excellent . thank you .\n",
            " Q goodbye . hello . how can i help you ? A hi assistant . i would like to order some pasta , please , for one person for takeout . can you help me ?\n",
            " Q i can help you with your takeout order . what kind of pasta would you like ? A i would like linguini with white clam sauce , and a side order of broccoli and parmesan cheese on that , and also a salad .\n",
            " Q okay here s what i have , linguine with white clam sauce a side order of broccoli with parmesan cheese and a salad . what type of dressing would you like with your salad ? A i would like ranch , please .\n",
            " Q i will be sure , they have ranch for your salad . anything else ? A nothing else . thank you .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A great . i ll be right there .\n",
            " Q enjoy your meal . A thank you . see you .\n",
            " Q you re welcome . bye . see you later . how can i help you ? A i d like to order mexican for two .\n",
            " Q i can help with that . what would you like to order in mexican cuisine ? A can i please get one order of stuffed chicken medallions and pork tenderloin abracadabra ?\n",
            " Q anything else before i confirm your order ? A can i get two iced teas ?\n",
            " Q is that it ? A that s all i need .\n",
            " Q just to confirm , you would like to order one order of stuffed chicken medallions and one order of pork tenderloin abracadabra along with iced teas ? A yes , that s correct .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A perfect . thank you .\n",
            " Q you re welcome . goodbye . hi . how can i help you ? A hi . i d like to order takeout for three people , please .\n",
            " Q okay and what would you like to order ? A extra large supreme pizza , please . cheesy breadsticks . and a litres bottle of orange soda . and that s about it .\n",
            " Q extra large supreme pizza , cheesy bread sticks and a litres bottle of orange soda , is that correct ? A yes , that is the correct order .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A alright . thank you very much for your help . i appreciate it .\n",
            " Q no problem . bye . A hi .\n",
            " Q hello . A i d like to get three burritos grande for takeout .\n",
            " Q three grande burritos for takeout , right ? A yeah , i d like the first one to be pork , mild .\n",
            " Q okay . A and the second one to be of beef , mild and the third carne asada , spicy .\n",
            " Q alright , anything else ? A yeah , let me get a large side of guacamole .\n",
            " Q and guacamole too , right ? A alright .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A alright . i ll be there .\n",
            " Q okay . i hope you enjoy your meal today . A thanks a lot .\n",
            " Q my pleasure . A talk to you later .\n",
            " Q hi . how can i help you ? i can help with that . what would you like to order ? A i would like to order food for one person ?\n",
            " Q i would like to like to order food for one person ? euros for one person . what kind ? A yes . the regular lamb gyro , but i don t want any tomatoes on it and extra tzatziki sauce . can i get some fries with that ?\n",
            " Q just to confirm , you wanted regular lamb gyro with extra tzatziki sauce and no tomatoes . also a side of fries . A yes , and can i get a diet coke with that , too ?\n",
            " Q diet coke added to the order . anything else ? A ah , no . that s all i need .\n",
            " Q let me confirm your order once again . you wanted regular lamb gyro with extra tzatziki sauce and no tomatoes . also a side of fries and diet coke ? A yes , that s it . that s perfect .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you .\n",
            " Q you re welcome . good bye . A bye .\n",
            " Q hi , how can i help you ? A i d like to take out some italian food .\n",
            " Q what would you like to order in italian food and for how many people ? A just get me some spaghetti for one person with some garlic toast and some coca cola .\n",
            " Q is that it ? anything else ? A nope , that ll be it . thank you very much .\n",
            " Q okay , just to confirm . you would like to order one spaghetti with garlic toast and a coca cola , is that correct ? A that s correct .\n",
            " Q okay , i have your details on file . your order will be ready for pick up in about minutes . A okay , thank you very much .\n",
            " Q your welcome . goodbye . hi there , how may i help you ? A i d like to order some food for takeout for one person .\n",
            " Q sure , you want to order some take out for one person ? A yes , some burgers , please .\n",
            " Q burgers , sure . A let s see .\n",
            " Q a mushroom burger with pickles lettuce tomatoes , a side of french fries and a diet coke . got it . A that s correct . and , can i get an apple pie for dessert ?\n",
            " Q yes . A thank you .\n",
            " Q apple pie for dessert ? A correct .\n",
            " Q your total is . A okay , no problem .\n",
            " Q great . A i ll pick it up soon . when is it ready for pickup ?\n",
            " Q the food is ready in approximately minutes . enjoy ! A great , thank you so much .\n",
            " Q hi . how can i help you ? A hey , i m looking to get some sandwiches .\n",
            " Q for how many people ? A just one .\n",
            " Q go ahead with your order . A can i get two reubens , two blts with medium water ?\n",
            " Q do you want ice water ? A no .\n",
            " Q sorry , it s okay . sorry , can you repeat that once ? A can i get extra pickles on the one blt ?\n",
            " Q yes , sure . A okay\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A alright . thank you . bye .\n",
            " Q goodbye . A hi . i was wondering if you can help me make a take out order .\n",
            " Q okay . A i need gyros for three people . my first order is lamb gyro with tzatziki sauce with fries .\n",
            " Q i m sorry what kind of sauce is that ? A that s the tzatziki sauce .\n",
            " Q okay , what is your second order ? A for the second order , i need just a beef gyro with an order of chips with that one .\n",
            " Q and what is the third one ? A another beef roll , but this one with fries . and let me get three large cokes with that , too .\n",
            " Q okay . one second . one lamb gyro with tzatziki sauce with fries , beef gyros with chip and fries and large cokes ? A yeah , that s it .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A okay , thank you .\n",
            " Q enjoy your meal . A i want to order takeout .\n",
            " Q got it . what are you looking for ? A i m looking food just for me . and i want pasta .\n",
            " Q i have an order that was interrupted from previous . A pasta . what was it ?\n",
            " Q yes , i have pasta orders . A what was my last one ?\n",
            " Q please proceed . A i need to know where that ordered .\n",
            " Q meatball pastas and a coke . A okay . could you add garlic bread to that order ?\n",
            " Q anything else ? A that s it , i believe .\n",
            " Q food for persons meatball pastas , one large coke , one garlic bread . A correct .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A perfect . thank you .\n",
            " Q bye . talk to you next time . how can i help you ? perfect . i have your personal details on file . your order will be ready for pick up in about minutes . A hi , i want to order pasta takeout for one person .\n",
            " Q okay , what would you like to order ? A i think i was going to order a plate of chicken alfredo with extra alfredo sauce and some garlic bread and how about a liters of pepsi ? and that will be it .\n",
            " Q one order of chicken alfredo with extra alfredo sauce , garlic bread and a liters of pepsi . does that sound correct ? A yep , that is correct . okay , thank you .\n",
            " Q you re welcome . bye . hello . how can i help you ? A hi , i would like help ordering takeout food for three people .\n",
            " Q okay , takeout for . what would you like to order ? A i would like to order mexican food .\n",
            " Q okay , what kind of mexican food ? A i would like to order six tacos .\n",
            " Q tacos , okay . anything else ? A that ll be all .\n",
            " Q just tacos . got it . A yes .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A all right , thank you .\n",
            " Q thank you . A hi , i was wondering if you could help me in ordering some takeout food .\n",
            " Q hi . i can help you with that . what would you like to order ? A i wanted to order three barbecue .\n",
            " Q okay , could you give some more specifications about your order ? A okay , for the first order , i d like two barbecue sandwiches with no coleslaw on them and an order of fries . for my second order , i d like a chopped barbecue plate . and for my third order , i d like a sliced barbecue plate .\n",
            " Q anything else ? A yeah , i d like to get a extra order of large hush puppies .\n",
            " Q could you repeat that please ? A yeah , i d also like to get some iced tea . how does that come ? does that come in gallons , or do i have to order individually ?\n",
            " Q tea comes bottled . A okay , then let me get three teas .\n",
            " Q okay , anything else ? A no , i think that ll do it .\n",
            " Q would you like your iced tea sweetened ? A yes , of course .\n",
            " Q barbecue sandwiches without coleslaw with order of fries and chopped barbecue plate and sliced barbecue plate and sweetened iced teas . A that s it .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A okay , thank you .\n",
            " Q bye . how can i help you ? A hello . i m looking to order takeout food for one person and i m looking to order some hot dogs .\n",
            " Q i can help you with your order for hot dogs , what would you like on your hot dogs ? A i need chili , cheese , ketchup , mustard . and then can i get onion and relish on the side ?\n",
            " Q okay , have one hot dog with chili cheese and mustard relish and onions on the side . A yep . that s it . that s all i needed . perfect .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A great ! thank you .\n",
            " Q bye . how can i help you ? A i need to place order for some great food for three people .\n",
            " Q i can help you with that . what would you like to order in greek food ? A for the first one i need some masaka .\n",
            " Q okay , next ? A i made a order of chicken masala also with the house salad with coleslaw dressing .\n",
            " Q anything else ? A i m here for the last order , i need the order of chicken kababs near dawn . let me get the three orders of bag they re buying there to you .\n",
            " Q can you repeat the last one ? A i wanted a order of chicken kebabs and then three orders of buckle bar for one for each one .\n",
            " Q let me confirm your order . A okay .\n",
            " Q you would like to order the following . chicken masala with house salad and house dressing . chicken masala with house salad and house dressing . A yeah .\n",
            " Q and chicken kababs , order of baklava . is that correct ? A that s it . that s all .\n",
            " Q okay , i have your personal details on file . your order will be ready for pick up in about minutes . A okay , thank you .\n",
            " Q you re welcome . bye . hello , how may i help you ? A hi , i d like to find a place to takeout order for two people at a good burger place .\n",
            " Q okay , what kind of burger ? A i need two cheeseburgers . one with pickles , lettuce , onion and cheese . the other one with just mustard , ketchup and cheese .\n",
            " Q just a moment . enjoy your meal . bye . one burger with with onion , lettuce , cheese and one burger one with just mustard , ketchup and cheese . A yes . and can i get a two orders of french fries and two cokes ?\n",
            " Q orders of fries and cokes . A yep .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A alright . thank you very much . bye . i d like to order some mexican food .\n",
            " Q okay , what would you like to order ? A i d like to have a taco and enchilada salad , five enchiladas and fried rice .\n",
            " Q okay , is there anything else ? A that ll be it . add one pepsi to it .\n",
            " Q okay . A that s correct .\n",
            " Q for how many people ? A just one person .\n",
            " Q alright , great . you got it . taco salad with enchiladas and fried rice ? A that s correct .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A okay . thank you very much .\n",
            " Q you re welcome . hi . how can i help you ? A hi . i want to order some food .\n",
            " Q how can i assist you with that ? A yeah , reorder some food . sarah s pizza , i guess .\n",
            " Q sarah s pizza . sure , let me bring that up . A okay .\n",
            " Q looks like you had large pizza with one half pepperoni and one half mushroom . is that right ? A that s right .\n",
            " Q anything else ? A i d like to add a brownie to the order , please .\n",
            " Q one chocolate brownie ? sure . i ve added that to the order . anything else ? A okay . thank you . that should be it .\n",
            " Q okay , let me confirm what you have large pizza with one half pepperoni and one half mushroom and brownie . your order will be ready for pick up in about minutes . A okay . thank you .\n",
            " Q goodbye . A hi . i d like to order food for take out for two people , the type of food i m looking at is soup .\n",
            " Q hi , how can i help you ? soup , what kind ? A i d like to order a clam chowder soup , a chicken noodle soup , and a side of grilled cheese sandwich . that would be all .\n",
            " Q anything else ? A no , that s it .\n",
            " Q let me confirm your order . you would like to order one clam chowder soup chicken noodle soup and the side of grilled cheese sandwich ? A yes , grilled cheese sandwich .\n",
            " Q is that correct ? A yes .\n",
            " Q anything else ? A no , that would be all .\n",
            " Q okay , i have your personal details on file . your order will be ready for pick up in about minutes . A thank you .\n",
            " Q your welcome , goodbye . A bye .\n",
            " Q how can i help you ? A hello assistant , i d like to order some takeout food for three people .\n",
            " Q okay , i can place that order . A great ! i d like to order some breakfast burritos .\n",
            " Q okay , what kind of burritos did you want ? could you repeat that please ? A and it should have hash browns on the side .\n",
            " Q hi . how can i help you ? A i want to order takeout .\n",
            " Q for how many people ? A i m going to need it for two people .\n",
            " Q what would you like to order ? A i want to get some thai food .\n",
            " Q okay . go ahead . A so , let me get some of the noodle special .\n",
            " Q anything else ? A and then let me get the chicken sauce with the noodles .\n",
            " Q any drinks or sides with that ? A let me get a coke .\n",
            " Q got it . A cool , that s it . that s all i need .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you .\n",
            " Q talk to you next time . bye . hi , how can i help you ? A hello . i need to order for three people and i need to order some breakfast burritos .\n",
            " Q go ahead . A i need three large bacon , egg , and cheese breakfast burritos with a side of guacamole sour cream and hot salsa .\n",
            " Q anything else ? A no , that s it .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in minutes . A perfect .\n",
            " Q until next time . bye . A thank you bye .\n",
            " Q hello . how can i help you ? A hi . i would like to order italian food for take out , please .\n",
            " Q for how many people ? A one person .\n",
            " Q got it . what would you like to order ? A i would like one large order of spaghetti with a side of parmesan .\n",
            " Q anything else ? A no , that will be all .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you , bye .\n",
            " Q you re welcome . bye . how may i help you ? A i want to order some tikka pizza .\n",
            " Q for how many ? A one person .\n",
            " Q is there anything else ? A yeah , i want to have mushrooms and beef .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A okay .\n",
            " Q goodbye . hi . how can i help you ? A hey . i want to get some barbecue .\n",
            " Q for how many people ? A for me and my girlfriend .\n",
            " Q and what would you and your girlfriend like ? A we could get some dressed ribs and some naked ribs .\n",
            " Q full racks or half racks ? A full racks .\n",
            " Q and any sides ? A no sides . make sure the dressed ribs are dressed with piedmont sauce .\n",
            " Q a order of dressed ribs with piedmont sauce , and an order of naked ribs . is that correct ? A yeah .\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in minutes . A all right . take care .\n",
            " Q until next time . bye . hi . how can i help you ? A hey , i need to order a couple of burgers .\n",
            " Q okay , sure thing . A okay , so i need to have two bacon blue cheese burgers . with mayo , onions , and fries .\n",
            " Q two bacon blue cheese burgers with mayo onions and fries and do you want anything to drink ? A okay . yeah , some coke or pepsi .\n",
            " Q some coke or pepsi ? sure thing . you got it . is this all correct ? A that s correct .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you .\n",
            " Q you re welcome . hi . how can i help you ? A hello . i m looking to order takeout food for three people . i m looking for mexican food .\n",
            " Q what would you like to order in mexican food ? A i need three large beef burritos with just cheese and sour cream , and i need to order three large diet cokes .\n",
            " Q anything else ? A that s it .\n",
            " Q so just to confirm you would like to order three large beef burritos with cheese and sour cream and diet cokes . is that correct ? A yep . that s correct .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A awesome . thank you .\n",
            " Q you re welcome . see you later . A hi . i would like to order food for takeout for two people . the type of food i m looking at is sandwiches .\n",
            " Q hello . what is your order ? A i would like to order a grilled habanero grill cheese sandwich , a turkey pastrami sandwich , a shrimp po boy sandwich . and two cans of oz diet mountain dew .\n",
            " Q okay . a grill habanero grill cheese sandwich , a turkey sandwich , shrimp po boy sandwich with cans of diet mountain dew . A yep . that is correct .\n",
            " Q okay . i have your details on file . your order will be ready for pick up in about minutes . A all right . thank you for assisting me .\n",
            " Q how can i help you ? A yes . i was looking to order thai food . roast duck curry for the entree .\n",
            " Q roast duck curry for the entree and side of jasmine rice . okay , anything else ? A yeah , could i get a side of jasmine rice ?\n",
            " Q okay . i have your personal details on file . your order will be ready for pick up in about minutes . A great . thank you very much .\n",
            " Q you re welcome . hello . A hi , i d like to order barbecue takeout for one .\n",
            " Q okay , one bbq take out . A yes . can i get a chopped barbecue sandwich with slaw and pickle ? and then a side of smoked wings and a side of baked beans .\n",
            " Q what was the last order ? A a side of baked beans .\n",
            " Q one bbq sandwich with a side coleslaw , barbecue wings and a side of baked beans . A yes , that s everything .\n",
            " Q ok . i have your personal details on file . your order will be ready for pick up in about minutes . A thank you . hey , do you remember last weekend when i got food from sarah s pizza ?\n",
            " Q food for people one large pepperoni pizza , one liter of sprite , two brownies and two iced teas . A yeah , that s absolutely right . can i also add two iced teas to that ?\n",
            " Q food for people one large pepperoni pizza , one liters of sprite , two brownies and four iced teas . A yep . sounds good .\n",
            " Q is there anything else you need ? A no , that s good . when will it be ready for pick up ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHLOyQ9E2Ts5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "639e0cf1-bced-4ed2-f87f-ecd26f064abf"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.12.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.22.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (49.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GqBEIwXoGpQq",
        "colab": {}
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions1 + answers1, target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRwJBJ85Dciy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcc6dfd2-b908-4841-8ea3-52a99848419c"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions1[20])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [14, 4, 6, 34, 35, 153, 136, 31, 141, 2, 35, 57, 47, 48, 122, 21, 118, 107, 13, 44, 126, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3AB6YFCDnTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions1, answers1 = tokenize_and_filter(questions1, answers1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjsojxVODyJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "005657e0-cb9a-4eba-a057-72415a6dc7fb"
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions1)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8611\n",
            "Number of samples: 38891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DB7X7PiDoUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions1,\n",
        "        'dec_inputs': answers1[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers1[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oOhuh8tEexC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eedf3f63-676d-4b1d-f88b-5d37d1d8081e"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ({inputs: (None, 40), dec_inputs: (None, 39)}, {outputs: (None, 39)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqDAhUJEg8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LTs5chExAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VKpsR-FHVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsaIYkf0FLCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BED5y4YFSPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqX_dqYCFfeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tguZtIKFuu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HFSma3F_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73I5VbJGD-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cE7vkaGGg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VBZCQjGUlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTRJel9Ga8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxhBOxYGcue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUssHnwGlCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFNX-Ovo278",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1QIgVNGpHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5e76373-245c-4605-edc3-d10ca58fa6ab"
      },
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.3097 - accuracy: 0.2296\n",
            "Epoch 2/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.3005 - accuracy: 0.2318\n",
            "Epoch 3/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.2918 - accuracy: 0.2337\n",
            "Epoch 4/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.2831 - accuracy: 0.2360\n",
            "Epoch 5/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2759 - accuracy: 0.2377\n",
            "Epoch 6/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2686 - accuracy: 0.2392\n",
            "Epoch 7/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.2616 - accuracy: 0.2411\n",
            "Epoch 8/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2557 - accuracy: 0.2426\n",
            "Epoch 9/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2499 - accuracy: 0.2440\n",
            "Epoch 10/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.2442 - accuracy: 0.2457\n",
            "Epoch 11/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2385 - accuracy: 0.2470\n",
            "Epoch 12/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2341 - accuracy: 0.2481\n",
            "Epoch 13/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.2288 - accuracy: 0.2495\n",
            "Epoch 14/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.2248 - accuracy: 0.2503\n",
            "Epoch 15/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2206 - accuracy: 0.2516\n",
            "Epoch 16/40\n",
            "608/608 [==============================] - 20s 33ms/step - loss: 0.2166 - accuracy: 0.2527\n",
            "Epoch 17/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2123 - accuracy: 0.2538\n",
            "Epoch 18/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.2086 - accuracy: 0.2548\n",
            "Epoch 19/40\n",
            "608/608 [==============================] - 20s 33ms/step - loss: 0.2056 - accuracy: 0.2556\n",
            "Epoch 20/40\n",
            "608/608 [==============================] - 20s 33ms/step - loss: 0.2019 - accuracy: 0.2566\n",
            "Epoch 21/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1990 - accuracy: 0.2573\n",
            "Epoch 22/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1950 - accuracy: 0.2584\n",
            "Epoch 23/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1919 - accuracy: 0.2593\n",
            "Epoch 24/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1890 - accuracy: 0.2601\n",
            "Epoch 25/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1864 - accuracy: 0.2609\n",
            "Epoch 26/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.1842 - accuracy: 0.2614\n",
            "Epoch 27/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1812 - accuracy: 0.2623\n",
            "Epoch 28/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1784 - accuracy: 0.2632\n",
            "Epoch 29/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1767 - accuracy: 0.2636\n",
            "Epoch 30/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1743 - accuracy: 0.2642\n",
            "Epoch 31/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1720 - accuracy: 0.2648\n",
            "Epoch 32/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1699 - accuracy: 0.2656\n",
            "Epoch 33/40\n",
            "608/608 [==============================] - 19s 31ms/step - loss: 0.1679 - accuracy: 0.2658\n",
            "Epoch 34/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.1656 - accuracy: 0.2665\n",
            "Epoch 35/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.1637 - accuracy: 0.2673\n",
            "Epoch 36/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1619 - accuracy: 0.2677\n",
            "Epoch 37/40\n",
            "608/608 [==============================] - 20s 32ms/step - loss: 0.1602 - accuracy: 0.2683\n",
            "Epoch 38/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1578 - accuracy: 0.2688\n",
            "Epoch 39/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1563 - accuracy: 0.2691\n",
            "Epoch 40/40\n",
            "608/608 [==============================] - 19s 32ms/step - loss: 0.1537 - accuracy: 0.2700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7c30bb2c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2W874bBHCXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpmbuOWHMzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b31791d8-f93b-455f-eb8b-98512c355414"
      },
      "source": [
        "output = predict('your order will be ready in a minute?')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: your order will be ready in a minute?\n",
            "Output: okay , thank you .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}